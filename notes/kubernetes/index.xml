<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on Vladimir Varankin</title><link>https://vladimir.varank.in/notes/kubernetes/</link><description>Recent content in Kubernetes on Vladimir Varankin</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 01 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://vladimir.varank.in/notes/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Env variables, you will (likely) find set in my Kubernetes deployments</title><link>https://vladimir.varank.in/notes/2023/05/env-variables-you-will-likely-find-set-in-my-kubernetes-deployments/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2023/05/env-variables-you-will-likely-find-set-in-my-kubernetes-deployments/</guid><description>&lt;p&gt;Kubernetes allows us to pass the values declared in a Pod&amp;rsquo;s manifest, to its containers via environment variables (&lt;a href="https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/"&gt;docs&lt;/a&gt;). A typical situation, where I find this handy is when I run a Go application in a Pod.&lt;/p&gt;
&lt;p&gt;As discussed in the previous note, out of the box, &lt;a href="https://vladimir.varank.in/notes/2023/01/go-runtime-vs-cfs-quota/"&gt;Go runtime isn&amp;rsquo;t aware if it runs inside a container&lt;/a&gt;. This can lead to confusing situations, when the runtime adjusts its behaviour, after observing the resources (CPU and memory) available on the cluster&amp;rsquo;s node, instead of the resources, a developer or an operator restricted the deployment with.&lt;/p&gt;</description></item><item><title>Go runtime vs CFS quota</title><link>https://vladimir.varank.in/notes/2023/01/go-runtime-vs-cfs-quota/</link><pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2023/01/go-runtime-vs-cfs-quota/</guid><description>&lt;p&gt;As of today, the Go runtime isn&amp;rsquo;t aware if it runs inside a container under the resource constraints (CPU or memory). The runtime sees the resources available for the container&amp;rsquo;s underlying host OS, e.g. the VM where the container runs, and tries to optimize its behaviour base on what it sees. For container runtimes on Linux, which implements the CPU restrictions via CFS (&amp;ldquo;Completely Fair Scheduler&amp;rdquo;), a mismatch in what the application thinks is has, and what the OS allows to use, can lead to the poor performance of the application after the unexpected throttling.&lt;/p&gt;
&lt;p&gt;For example, a Go application, that runs in a container, constrained with 0.5 CPU, running on a host with 2 CPU, will observe 2 available CPU cores. That is the application&amp;rsquo;s calls to &lt;a href="https://pkg.go.dev/runtime#NumCPU"&gt;&lt;code&gt;runtime.NumCPU()&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://pkg.go.dev/runtime#GOMAXPROCS"&gt;&lt;code&gt;runtime.GOMAXPROCS()&lt;/code&gt;&lt;/a&gt; will get us &amp;ldquo;2&amp;rdquo;. Because the Go runtime is optimized for the maximum utilization of the available compute under the concurrent workload, the goroutines it spawns are distributed to the internal thread pool, created with the assumption of two available CPU cores. This causes the application to throttle after the sum of the time it spend on the CPU cores per CFS period become equals to the quota of the container. With &lt;a href="https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html#management"&gt;the default CFS period&lt;/a&gt; 100ms, the CFS quota of this container 0.5 CPU, and two threads running on different CPU cores, the application is throttled after 25ms every 100ms.&lt;/p&gt;</description></item><item><title>Bookmarks (issue 10)</title><link>https://vladimir.varank.in/notes/2022/12/bookmarks-10/</link><pubDate>Sat, 31 Dec 2022 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2022/12/bookmarks-10/</guid><description>&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ZZkMN6cbL-U"&gt;The 22 BEST Basslines of 2022&lt;/a&gt; (Patrick Hunter).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://boyter.org/posts/how-i-built-my-own-index-for-searchcode/"&gt;Building a custom code search index in Go for searchcodecom&lt;/a&gt; (&lt;a href="https://twitter.com/boyter"&gt;Ben Boyter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://medium.com/directeam/kubernetes-resources-under-the-hood-part-3-6ee7d6015965"&gt;Kubernetes resources under the hood&lt;/a&gt;. This year was rich for deep tech articles and talks, that explain how CPU requests and limits work in Kubernetes. This three-part series is no exception.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/ID_AA_Carmack/status/1603931899810004994"&gt;John Carmack on resigning from Meta&lt;/a&gt;. A post that spawned many intresting opinions on the internet: &amp;ldquo;You can&amp;rsquo;t have top people in X (performance, security, whatever) work for you and only half-care about X at the same time. They will move&amp;rdquo;.&lt;/p&gt;</description></item><item><title>Bookmarks (issue 9)</title><link>https://vladimir.varank.in/notes/2022/11/bookmarks-9/</link><pubDate>Wed, 30 Nov 2022 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2022/11/bookmarks-9/</guid><description>&lt;p&gt;&lt;a href="https://kubernetes.io/blog/2022/11/18/upcoming-changes-in-kubernetes-1-26/"&gt;Kubernetes removals, deprecations, and major changes in 1.26&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://medium.com/@kewynakshlley/performance-evaluation-of-the-autoscaling-strategies-vertical-and-horizontal-using-kubernetes-42d9a1663e6b"&gt;Performance evaluation of autoscaling strategies in Kubernetes&lt;/a&gt; (&lt;a href="https://twitter.com/kewynakshlley"&gt;Kewyn Akshlley&lt;/a&gt;). tl;dr; After comparing the performance of horizontal and vertical autoscaling using synthetic load, the horizontal autoscaling seems more efficient, reacts faster to the load variation, and results in a lower impact on the application&amp;rsquo;s response time.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://changelog.com/gotime/257"&gt;How Pinterest delivers software at scale&lt;/a&gt; (Go Time, podcast). A very refreshing discussion about real-world technical challenges large organizations face.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.se-radio.net/2022/11/episode-539-adam-dymitruk-on-event-modeling/"&gt;Adam Dymitruk on Event Modeling&lt;/a&gt; (Software Engineering Radio, podcast). &lt;a href="https://eventmodeling.org/posts/what-is-event-modeling/"&gt;Event Modeling: what is it?&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Bookmarks (issue 6)</title><link>https://vladimir.varank.in/notes/2022/08/bookmarks-6/</link><pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2022/08/bookmarks-6/</guid><description>&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=x9_9iaVszpM"&gt;Kubernetes antipatterns: CPU Limits&lt;/a&gt;. Always define CPU requests; never define CPU limits.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.depesz.com/2021/06/20/explaining-the-unexplainable-part-6-buffers/"&gt;Explaining the unexplainable: buffers in PostgreSQL&lt;/a&gt;. Shared buffers are those, which&amp;rsquo;re&amp;rsquo; &amp;ldquo;shared&amp;rdquo; between several DB sessions, i.e. data pages, indices, etc; local buffers, are &amp;ldquo;local&amp;rdquo; to a session, i.e. for temporal tables; temp buffers are for intermediate objects, i.e. when the DBMS does hashing and sorting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.geekabyte.io/2022/08/rust-iterator-pattern-with-iter.html"&gt;Rust Iterator pattern with &lt;code&gt;iter()&lt;/code&gt;, &lt;code&gt;into_iter()&lt;/code&gt; and &lt;code&gt;iter_mut()&lt;/code&gt; methods&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/golang/go/discussions/54245"&gt;Standard iterator interface in Go&lt;/a&gt; (Ian Lance Taylor via GitHub Discussions).&lt;/p&gt;</description></item><item><title>Bookmarks (issue 1)</title><link>https://vladimir.varank.in/notes/2022/03/bookmarks-1/</link><pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2022/03/bookmarks-1/</guid><description>&lt;p&gt;&lt;a href="https://planetscale.com/blog/generics-can-make-your-go-code-slower"&gt;Generics can make your Go code slower&lt;/a&gt; (PlanetScale):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;boxing vs monomorphization vs partial monomorphization (&amp;ldquo;GCShape stenciling with Dictionaries&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;interface inlining doesn&amp;rsquo;t work well with the 1.18&amp;rsquo;s compiler&lt;/li&gt;
&lt;li&gt;generics work well for byte sequences (&lt;code&gt;string | []byte&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;in simple cases, generics can be useful for function callbacks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://engineering.fb.com/2022/03/30/security/de-identified-authentication-at-scale/"&gt;How Meta enables de-identified authentication at scale&lt;/a&gt;. The rational, the use-cases, and a high-level architecture of Meta&amp;rsquo;s Anonymous Credential Service (ACS).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/blogs/database/hidden-dangers-of-duplicate-key-violations-in-postgresql-and-how-to-avoid-them/"&gt;Hidden dangers of duplicate key violations in PostgreSQL&lt;/a&gt; (AWS). &lt;code&gt;INSERT â€¦ ON CONFLICT&lt;/code&gt; has additional benefits, if compared to relying on PostgreSQL&amp;rsquo;s &amp;ldquo;duplicate key violation&amp;rdquo; error:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;no additional space needed for dead tuples&lt;/li&gt;
&lt;li&gt;less autovacuum required&lt;/li&gt;
&lt;li&gt;transaction IDs aren&amp;rsquo;t used for nothing, preventing (postponing) the potential trx-id wraparound.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/blogs/containers/diving-into-iam-roles-for-service-accounts/"&gt;Diving into AWS IAM Roles for (Kubernetes) Service Accounts (IRSA)&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Making sense of requests for CPU resources in Kubernetes</title><link>https://vladimir.varank.in/notes/2021/09/making-sense-of-requests-for-cpu-resources-in-kubernetes/</link><pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2021/09/making-sense-of-requests-for-cpu-resources-in-kubernetes/</guid><description>&lt;p&gt;Kubernetes allows a container to request several resource types:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
 name: my-app
spec:
 containers:
 - name: my-app
 image: images.example/my-app
 resources:
 requests:
 cpu: &amp;#34;100m&amp;#34;
 memory: &amp;#34;64Mi&amp;#34;
 limits:
 cpu: &amp;#34;500m&amp;#34;
 memory: &amp;#34;128Mi&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One particularly confusing type of the resource for me was &lt;code&gt;cpu&lt;/code&gt;. For example, in the manifest above, the &lt;code&gt;my-app&lt;/code&gt; container declares a request for &amp;ldquo;100m&amp;rdquo; of the CPU. What does that mean?&lt;/p&gt;</description></item><item><title>k3s with Ubuntu Server (arm64) on Raspberry Pi 4</title><link>https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/</link><pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/</guid><description>&lt;p&gt;As I&amp;rsquo;ve &lt;a href="https://twitter.com/tvii/status/1215927299557797893?s=20"&gt;twitted&lt;/a&gt; recently, I&amp;rsquo;m updating one of my Raspberry Pis to &lt;a href="https://ubuntu.com/download/raspberry-pi"&gt;Ubuntu Server 19.10 (arm64)&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="one-of-raspberry-pis"&gt;&amp;ldquo;One of Raspberry Pis&amp;rdquo;?&lt;/h2&gt;
&lt;p&gt;My home cluster is four &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-2gb"&gt;Raspberry Pis 4 (2GB)&lt;/a&gt;; all connected to my internet router through ethernet and
powered with &lt;a href="https://www.amazon.de/gp/product/B00PTLSH9G/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&amp;amp;psc=1"&gt;60W 6 USB-ports charger&lt;/a&gt;. All Pis build a small Kubernetes cluster that runs with &lt;a href="https://k3s.io/"&gt;k3s&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All by one Pis run on &lt;a href="https://www.raspberrypi.org/downloads/raspbian/"&gt;Raspbian Buster Lite&lt;/a&gt; and this setup&amp;rsquo;s been working pretty well until I&amp;rsquo;ve found out,
&lt;a href="https://www.aerospike.com/"&gt;Aerospike&lt;/a&gt;, a database I required to run for a testing lab, only works on a 64-bit OS.&lt;/p&gt;
&lt;p&gt;Luckily, &lt;a href="https://ubuntu.com/download/raspberry-pi"&gt;Ubuntu Server has an arm64 version&lt;/a&gt; built for Raspberry Pi. Thus, my working plan is to switch one Pi
to Ubuntu, compile and run a single-instance Aerospike server (&lt;em&gt;and any other components, that require a 64-bit OS&lt;/em&gt;) on this Pi, and provide a Kubernetes service in front of the DB, so other components in the cluster could access it as if it was
fully managed by Kubernetes.&lt;/p&gt;</description></item></channel></rss>