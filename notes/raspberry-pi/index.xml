<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Raspberry Pi on Vladimir Varankin</title><link>https://vladimir.varank.in/notes/raspberry-pi/</link><description>Recent content in Raspberry Pi on Vladimir Varankin</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sat, 10 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://vladimir.varank.in/notes/raspberry-pi/index.xml" rel="self" type="application/rss+xml"/><item><title>Self-signed certificates with k3s and cert-manager</title><link>https://vladimir.varank.in/notes/2021/07/self-signed-certificates-with-k3s-and-cert-manager/</link><pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2021/07/self-signed-certificates-with-k3s-and-cert-manager/</guid><description>&lt;p&gt;At least for now, my homelab cluster (&lt;a href="https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/"&gt;4x Raspberry Pi, k3s, etc&lt;/a&gt;) is available only for the devices &lt;a href="https://vladimir.varank.in/notes/2021/04/wireless-to-ethernet-island-for-homelab-cluster-ipv6-ndp-proxy-and-mdns-reflector/"&gt;on my local network&lt;/a&gt;, inside a custom DNS zone &lt;code&gt;k8s.pi.home&lt;/code&gt;. I don&amp;rsquo;t think there are practical reasons to run anything with HTTPS in that setup, but there are cases, like browser extensions, where it&amp;rsquo;s required.&lt;/p&gt;
&lt;p&gt;Turned out, in 2021, it&amp;rsquo;s fairly straight forward to set up a Certificate Authority (CA), that will issue TLS certificates to &amp;ldquo;secure&amp;rdquo; the ingress resources. At least, it&amp;rsquo;s way simpler comparing to how I remember it was back in the days. All thanks to &lt;a href="https://cert-manager.io"&gt;cert-manager&lt;/a&gt; and some YAML.&lt;/p&gt;
&lt;p&gt;First thing is to install cert-manager to the cluster. &lt;a href="https://rancher.com/docs/k3s/latest/en/helm/"&gt;k3s comes with helm-controller&lt;/a&gt;, that gives us a way to manage helm charts with Custom Resource Definitions (CRD). The following manifest defines a new namespace, and a resource of a kind &lt;code&gt;HelmChart&lt;/code&gt;, to install cert-manager inside this namespace:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;apiVersion: v1
kind: Namespace
metadata:
 name: cert-manager

---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
 name: cert-manager
 namespace: kube-system
spec:
 chart: cert-manager
 repo: https://charts.jetstack.io
 targetNamespace: cert-manager
 valuesContent: |-
 installCRDs: true
 prometheus:
 enabled: true
 servicemonitor:
 enabled: true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After applying the manifest above — &lt;code&gt;kubectl apply -f cert-manager.yml&lt;/code&gt; — define a self-signed certificate, which is used to bootstrap a CA:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
 name: selfsigned-cluster-issuer
spec:
 selfSigned: {}

---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
 name: selfsigned-ca
spec:
 isCA: true
 commonName: selfsigned-ca
 secretName: selfsigned-ca-root-secret
 privateKey:
 algorithm: ECDSA
 size: 256
 issuerRef:
 name: selfsigned-cluster-issuer
 kind: ClusterIssuer
 group: cert-manager.io

---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
 name: selfsigned-issuer
spec:
 ca:
 secretName: selfsigned-ca-root-secret
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now, I can use &lt;code&gt;selfsigned-issuer&lt;/code&gt; to issue TLS certificates for the ingress resources (&lt;em&gt;Traefik ingress in the k3s&amp;rsquo;s case&lt;/em&gt;). E.g. to play around, I run an open-source version of &lt;a href="https://languagetool.org/dev"&gt;LanguageTool&lt;/a&gt; server. The ingress manifests for the server looks like as following:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
 name: languagetool-server
 annotations:
 kubernetes.io/ingress.class: traefik
 cert-manager.io/issuer: selfsigned-issuer
spec:
 rules:
 - host: languagetool.k8s.pi.home
 http:
 paths:
 - path: /
 pathType: ImplementationSpecific
 backend:
 service:
 name: languagetool-server
 port:
 number: 8010
 tls:
 - hosts: [languagetool.k8s.pi.home]
 secretName: languagetool-server-cert
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of course, any certificate signed by my CA won&amp;rsquo;t be automatically trusted by anyone, including my own system. If I try to access &lt;code&gt;https://languagetool.k8s.pi.home&lt;/code&gt;, any HTTP client will raise a &amp;ldquo;failed to verify the legitimacy of the server&amp;rdquo; issue. I don&amp;rsquo;t know if there is a better way to solve that, but I can hack that around by installing the cluster&amp;rsquo;s root CA certificate into the system&amp;rsquo;s keychain, and telling the system, that it should &amp;ldquo;trust&amp;rdquo; the certificate:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ kubectl get secret/selfsigned-ca-root-secret -o json \
 | jq -r &amp;#39;.data[&amp;#34;ca.crt&amp;#34;]&amp;#39; \
 | base64 -D &amp;gt; ~/tmp/selfsigned-root-ca.crt
$ open ~/tmp/selfsigned-root-ca.crt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Choose &amp;ldquo;Always trust&amp;rdquo; the certificate in the keychain&amp;rsquo;s certificate settings. The server looks &lt;em&gt;legitimate&lt;/em&gt; now!&lt;/p&gt;</description></item><item><title>Wireless-to-Ethernet island for homelab cluster: IPv6, NDP proxy and mDNS reflector</title><link>https://vladimir.varank.in/notes/2021/04/wireless-to-ethernet-island-for-homelab-cluster-ipv6-ndp-proxy-and-mdns-reflector/</link><pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2021/04/wireless-to-ethernet-island-for-homelab-cluster-ipv6-ndp-proxy-and-mdns-reflector/</guid><description>&lt;p&gt;Initially, when I assembled &lt;a href="https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/"&gt;a homelab cluster of Raspberry Pis&lt;/a&gt;, everything was directly connected to my Wi-Fi router with the Ethernet cables. This worked fine but this &amp;ldquo;stack of boards&amp;rdquo; behind the sofa in the centre of our small flat bugged me a bit.&lt;/p&gt;
&lt;p&gt;Last year I decided to reorganise the cluster, turning it into a &lt;em&gt;wireless-to-wired island&lt;/em&gt;, which I could relocate anywhere within the flat, without doing any special cable management, while staying cheap and avoid stacking the appartment with even more gadgets. After going through a number of trials and errors, the final setup looks as the following:&lt;/p&gt;
&lt;figure&gt;&lt;img src="https://vladimir.varank.in/images/2021/homelab-pi-net-1.png"
 alt="Homelab cluster as a wireless-to-ethernet island (2021)" width="820"&gt;
&lt;/figure&gt;

&lt;p&gt;Different colours contour the connections between two logical subnets — more on that later. Here what we have on the schema (top to bottom):&lt;/p&gt;</description></item><item><title>Building Multi-Platform Docker Images with Travis CI and BuildKit</title><link>https://vladimir.varank.in/notes/2020/01/buildkit-multi-platform-travis-ci/</link><pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2020/01/buildkit-multi-platform-travis-ci/</guid><description>&lt;p&gt;&lt;em&gt;This is a lengthy note. If you don&amp;rsquo;t quite feel reading and only need the working example, go directly to &lt;a href="https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/.travis.yml"&gt;the Travis CI build file&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The more I delve into the world of Raspberry Pi, the more I notice that &amp;ldquo;regular and boring&amp;rdquo; things on ARM are harder than I expected.&lt;/p&gt;
&lt;p&gt;People build and distribute software exclusively for amd64. You read another &amp;ldquo;&lt;em&gt;Kubernetes something&lt;/em&gt;&amp;rdquo; tutorial, that went viral on Twitter, and is fancy to try it out. Still, all helm charts, or whatever the author prefered, use Docker images built exclusively for amd64.&lt;/p&gt;
&lt;p&gt;Docker toolchain has added the support for building multi-platform images in 19.x. However, it&amp;rsquo;s available only under the &amp;ldquo;experimental&amp;rdquo; mode. The topic of building multi-platform Docker images yet feels underrepresented.&lt;/p&gt;
&lt;h2 id="but-first-what-are-multi-platform-docker-images"&gt;But first, what are multi-platform Docker images?&lt;/h2&gt;
&lt;p&gt;When a client, e.g. Docker client, tries to pull an image, it must negotiate the details about what exactly to pull with the registry. The registry provides a manifest that describes the digest of the requested image, the volumes the image consists of, the platform this image can run on, etc. Optionally, the registry can provide a manifests list, which, as the name suggests, is a list of several manifests bundled into one. With the manifests list in hands, the client can figure out the particular digest of the image it needs to pull.&lt;/p&gt;
&lt;p&gt;So multi-platform Docker images are just several images, whose manifests are bundled into the manifests list.&lt;/p&gt;
&lt;p&gt;Imagine we want to pull the image &lt;a href="https://hub.docker.com/_/golang"&gt;&lt;code&gt;golang:1.13.6-alpine3.10&lt;/code&gt;&lt;/a&gt;. Docker client will get the manifests list from Dockerhub. This list includes digests of several images, each built for the particular platform. If we&amp;rsquo;re on Raspberry Pi, running the current Raspbian Linux, which is &lt;code&gt;arm/v7&lt;/code&gt;, the client will pick the corresponding image&amp;rsquo;s digest. Alternatively, we could choose to pull the image &lt;a href="https://hub.docker.com/r/arm32v7/golang/"&gt;&lt;code&gt;arm32v7/golang:1.13.6-alpine3.10&lt;/code&gt;&lt;/a&gt; instead, and we ended up with the same image with the &lt;a href="https://hub.docker.com/layers/arm32v7/golang/alpine3.10/images/sha256-d72fa60fb5b9ffc12db9c87340bc9d9f55852570f1efc7d7656f081749a7f0aa"&gt;digest &lt;code&gt;d72fa60fb5b9&lt;/code&gt;&lt;/a&gt;. Of course, to use a single universal image name, i.e. &lt;code&gt;golang&lt;/code&gt;, on every platform is way more convenient.&lt;/p&gt;
&lt;p&gt;You can read more about manifests &lt;a href="https://docs.docker.com/registry/spec/manifest-v2-2/"&gt;in Docker registry documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="does-it-mean-i-need-to-build-different-docker-images-for-each-platform-i-want-to-support"&gt;Does it mean I need to build different Docker images, for each platform I want to support?&lt;/h2&gt;
&lt;p&gt;Well, yes. This is how, official images are built.&lt;/p&gt;
&lt;p&gt;For every platform, the image is built and pushed to the registry under the name &lt;code&gt;&amp;lt;platform&amp;gt;/&amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt;&lt;/code&gt;, e.g. &lt;a href="https://hub.docker.com/r/amd64/golang/"&gt;&lt;code&gt;amd64/golang:1-alpine&lt;/code&gt;&lt;/a&gt;. And next, a manifests list, that combines all those platform-specific images, is built and pushed with the simple name &lt;code&gt;&amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/moby/buildkit"&gt;Docker&amp;rsquo;s BuildKit&lt;/a&gt; provides a toolkit that, among other nice things, allows building multi-platform images on a single host. BuildKit is used inside &lt;a href="https://github.com/docker/buildx"&gt;Docker&amp;rsquo; buildx project&lt;/a&gt;, that is part of the recent Docker version.&lt;/p&gt;
&lt;p&gt;One can use buildx, but, for this post, I wanted to try out, what would it look like to use BuildKit directly. For &lt;a href="https://github.com/profefe/profefe"&gt;profefe&lt;/a&gt;, the system for continuous profiling of Go services, I set up &lt;a href="https://travis-ci.com/"&gt;Travis CI&lt;/a&gt;, that builds a multi-platform Docker image and pushes them to Dockerhub.&lt;/p&gt;
&lt;p&gt;profefe is written in Go. That simplifies things, because, thanks to Go compiler, I don&amp;rsquo;t have to think about how to compile code for different platforms. &lt;a href="https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/contrib/docker/Dockerfile"&gt;The same Dockerfile&lt;/a&gt; will work fine on every platform.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how &amp;ldquo;deploy&amp;rdquo; stage of the build job looks like (&lt;a href="https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/.travis.yml"&gt;see &lt;code&gt;travis.yml&lt;/code&gt; on profefe&amp;rsquo;s GitHub&lt;/a&gt;).&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;dist: bionic

language: go
go:
 - 1.x

jobs:
 include:
 - stage: deploy docker
 services: docker
 env:
 - PLATFORMS=&amp;#34;linux/amd64,linux/arm64,linux/arm/v7&amp;#34;
 install:
 - docker container run --rm --privileged multiarch/qemu-user-static --reset -p yes
 - docker container run -d --rm --name buildkitd --privileged moby/buildkit:latest
 - sudo docker container cp buildkitd:/usr/bin/buildctl /usr/local/bin/
 - export BUILDKIT_HOST=&amp;#34;docker-container://buildkitd&amp;#34;
 script: skip
 deploy:
 - provider: script
 script: |
 buildctl build \
 --progress=plain \
 --frontend=dockerfile.v0 \
 --local context=. --local dockerfile=. \
 --opt filename=contrib/docker/Dockerfile \
 --opt platform=$PLATFORMS \
 --opt build-arg:VERSION=\&amp;#34;master\&amp;#34; \
 --opt build-arg:GITSHA=\&amp;#34;$TRAVIS_COMMIT\&amp;#34; \
 --output type=image,\&amp;#34;name=profefe/profefe:git-master\&amp;#34;,push=true
 on:
 repo: profefe/profefe
 branch: master
 before_deploy:
 - echo &amp;#34;$DOCKER_PASSWORD&amp;#34; | docker login --username &amp;#34;$DOCKER_USERNAME&amp;#34; --password-stdin
 after_failure:
 - buildctl debug workers ls
 - docker container logs buildkitd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&amp;rsquo;s a lot happening here, but I&amp;rsquo;ll describe the most critical parts.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with &lt;code&gt;dist: bionic&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We run the builds under Ubuntu 18.04 (Bionic Beaver). To be able to build multi-platform images on a single amd64 host, BuildKit uses QEMU to emulate other platforms. That requires Linux kernel 4.8, so even Ubuntu 16.04 (Xenial Xerus) should work.&lt;/p&gt;
&lt;p&gt;The top-level details on how the emulation works are very well described in &lt;a href="https://www.kernel.org/doc/html/latest/admin-guide/binfmt-misc.html"&gt;https://www.kernel.org/doc/html/latest/admin-guide/binfmt-misc.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In short, we tell the component of the kernel (&lt;code&gt;binfmt_misc&lt;/code&gt;) to use QEMU when the system executes a binaries built for a different platform. The following call in the &amp;ldquo;install&amp;rdquo; step is what&amp;rsquo;s doing that:&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;- docker container run --rm --privileged multiarch/qemu-user-static --reset -p yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Under the hood, the container runs a &lt;a href="https://raw.githubusercontent.com/qemu/qemu/master/scripts/qemu-binfmt-conf.sh"&gt;shell script from QEMU project&lt;/a&gt;, that registers the emulator as an executor of binaries from the external platforms.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you think, that running a docker container to do the manipulations with the host&amp;rsquo;s OS looks weird, well&amp;hellip; I can&amp;rsquo;t agree more. Probably, a better approach would be to install &lt;a href="https://packages.ubuntu.com/bionic/qemu-user-static"&gt;qemu-user-static&lt;/a&gt;, which would do the proper setup. Unfortunately, the current package&amp;rsquo;s version for Ubuntu Bionic doesn&amp;rsquo;t do the registration as we need it. I.e. its post-install doesn&amp;rsquo;t add the &lt;code&gt;&amp;quot;F&amp;quot;&lt;/code&gt; flag (&amp;ldquo;fix binaries&amp;rdquo;), which is crucial for our goal. Let&amp;rsquo;s just agree,that docker-run will do ok for the demonstrational purpose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;- docker container run -d --rm --name buildkitd --privileged moby/buildkit:latest
- sudo docker container cp buildkitd:/usr/bin/buildctl /usr/local/bin/
- export BUILDKIT_HOST=&amp;#34;docker-container://buildkitd&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is another &amp;ldquo;docker-run&amp;rsquo;ism&amp;rdquo;. We start BuildKit&amp;rsquo;s &lt;code&gt;buildkitd&lt;/code&gt; daemon inside the container, attaching it to the Docker daemon that runs on the host (&amp;ldquo;privileged&amp;rdquo; mode). Next, we copy &lt;code&gt;buildctl&lt;/code&gt; binary from the container to the host system and set &lt;code&gt;BUILDKIT_HOST&lt;/code&gt; environment variable, so &lt;code&gt;buildctl&lt;/code&gt; knew where its daemon runs.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Alternatively, we could install BuildKit from GitHub and run the daemon directly on the build host. YOLO.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;before_deploy:
 - echo &amp;#34;$DOCKER_PASSWORD&amp;#34; | docker login --username &amp;#34;$DOCKER_USERNAME&amp;#34; --password-stdin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To be able to push the images to the registry, we need to log in providing Docker credentials to host&amp;rsquo;s Docker daemon. The credentials are set as Travis CI&amp;rsquo;s encrypted environment variables ([refer to Travis CI docs])](&lt;a href="https://docs.travis-ci.com/user/environment-variables/))"&gt;https://docs.travis-ci.com/user/environment-variables/))&lt;/a&gt;.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;buildctl build \
 --progress=plain \
 --frontend=dockerfile.v0 \
 --local context=. --local dockerfile=. \
 --opt filename=contrib/docker/Dockerfile \
 --opt platform=$PLATFORMS \
 --opt build-arg:VERSION=\&amp;#34;master\&amp;#34; \
 --opt build-arg:GITSHA=\&amp;#34;$TRAVIS_COMMIT\&amp;#34; \
 --output type=image,\&amp;#34;name=profefe/profefe:git-master\&amp;#34;,push=true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the &lt;em&gt;black box&lt;/em&gt; where everything happens. Magically!&lt;/p&gt;
&lt;p&gt;We run &lt;code&gt;buildctl&lt;/code&gt; stating that it must use the specified Dockerfile; it must build the images for defined platforms (I specified &lt;code&gt;linux/amd64,linux/arm64,linux/arm/v7&lt;/code&gt;), create a manifests list tagged as the desired image (&lt;code&gt;profefe/profefe:&amp;lt;version&amp;gt;&lt;/code&gt;), and push all the images to the registry.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;buildctl debug workers ls&lt;/code&gt; shows what platforms does BuildKit on this host support. I listed only those I&amp;rsquo;m currently intrested with.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s all. This setup automatically builds and pushes multi-platform Docker images for profefe (&lt;a href="https://hub.docker.com/p/profefe/profefe"&gt;https://hub.docker.com/p/profefe/profefe&lt;/a&gt;) on a commit to project&amp;rsquo;s &amp;ldquo;master&amp;rdquo; branch on GitHub.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;As I hope you&amp;rsquo;ve seen, support for multi-platform is getting easier and things that were hard a year ago are only mildly annoying now :)&lt;/p&gt;
&lt;p&gt;If you have any comments or suggestions, reach out to me on &lt;a href="https://twitter.com/tvii/status/1221858810006065154"&gt;Twitter&lt;/a&gt; or discuss this note on &lt;a href="https://www.reddit.com/r/docker/comments/eutrkg/building_multiplatform_docker_images_with_travis/"&gt;r/docker Reddit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some more reading on the topic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/moby/buildkit"&gt;Documentation for BuildKit project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/docker/buildx#building-multi-platform-images"&gt;Building multi-platform images with docker and buildx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/blog/docker-official-images-now-multi-platform/"&gt;Docker Official Images are now Multi-platform, Docker official announcement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>k3s with Ubuntu Server (arm64) on Raspberry Pi 4</title><link>https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/</link><pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate><guid>https://vladimir.varank.in/notes/2020/01/raspi-ubuntu-arm64-k3s/</guid><description>&lt;p&gt;As I&amp;rsquo;ve &lt;a href="https://twitter.com/tvii/status/1215927299557797893?s=20"&gt;twitted&lt;/a&gt; recently, I&amp;rsquo;m updating one of my Raspberry Pis to &lt;a href="https://ubuntu.com/download/raspberry-pi"&gt;Ubuntu Server 19.10 (arm64)&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="one-of-raspberry-pis"&gt;&amp;ldquo;One of Raspberry Pis&amp;rdquo;?&lt;/h2&gt;
&lt;p&gt;My home cluster is four &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-2gb"&gt;Raspberry Pis 4 (2GB)&lt;/a&gt;; all connected to my internet router through ethernet and
powered with &lt;a href="https://www.amazon.de/gp/product/B00PTLSH9G/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&amp;amp;psc=1"&gt;60W 6 USB-ports charger&lt;/a&gt;. All Pis build a small Kubernetes cluster that runs with &lt;a href="https://k3s.io/"&gt;k3s&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All by one Pis run on &lt;a href="https://www.raspberrypi.org/downloads/raspbian/"&gt;Raspbian Buster Lite&lt;/a&gt; and this setup&amp;rsquo;s been working pretty well until I&amp;rsquo;ve found out,
&lt;a href="https://www.aerospike.com/"&gt;Aerospike&lt;/a&gt;, a database I required to run for a testing lab, only works on a 64-bit OS.&lt;/p&gt;
&lt;p&gt;Luckily, &lt;a href="https://ubuntu.com/download/raspberry-pi"&gt;Ubuntu Server has an arm64 version&lt;/a&gt; built for Raspberry Pi. Thus, my working plan is to switch one Pi
to Ubuntu, compile and run a single-instance Aerospike server (&lt;em&gt;and any other components, that require a 64-bit OS&lt;/em&gt;) on this Pi, and provide a Kubernetes service in front of the DB, so other components in the cluster could access it as if it was
fully managed by Kubernetes.&lt;/p&gt;</description></item></channel></rss>