<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Notes - Vladimir Varankin</title><link rel=alternate type=application/rss+xml href=https://vladimir.varank.in/notes/index.xml title="Notes from Vladimir Varankin"><style>:root{--background-color: #fff;--text-color: #111;--header-color: #111;--link-color: rgb(0, 16, 161);--link-underline-color: rgba(0, 16, 161, 0.3);--link-hover-color: rgb(190, 0, 0);--link-hover-underline-color: rgba(190, 0, 0, 0.3)}@media(prefers-color-scheme:dark){:root.theme-dark{--background-color: #181818;--text-color: #cfcfcf;--header-color: #fefefe;--link-color: rgb(85, 172, 255);--link-underline-color: rgb(85, 172, 255, 0.8);--link-hover-color: rgb(231, 66, 66);--link-hover-underline-color: rgb(231, 66, 66, 0.8)}}body{background:var(--background-color);color:var(--text-color);font-family:Charter,Georgia,serif;font-size:16px;line-height:1.45;margin:8px 12px}h1,h2,h3,h4{color:var(--header-color);font-family:Athelas,Georgia,serif;line-height:1}h1{font-size:40px;margin:.5em 0 .2em}a{color:#0010a1;color:var(--link-color);text-decoration-color:var(--link-underline-color)}a:hover,a:active{color:#be0000;color:var(--link-hover-color);text-decoration-color:var(--link-hover-underline-color)}pre{line-height:1.3}code{font-family:Menlo,Consolas,monospace;font-size:14px}hr{border:none;border-bottom:1px solid;width:90%}.main-nav{letter-spacing:.3em;padding-bottom:16px}.main-nav a,.main-nav span{letter-spacing:0}.main-content{max-width:900px}.main-footer{margin:50px 0 0}.article{margin:0 0 50px}.article-meta{font-size:14px;line-height:1}.tag{margin:0 0 0 .7em}</style></head><body><nav class=main-nav><a href=/>Vladimir Varankin</a>
<a href=/notes class=item-current>Notes</a>
<a href=https://github.com/narqo>GitHub</a>
<a href=https://twitter.com/tvii>Twitter</a>
<a href=https://keybase.io/varankinv>Keybase</a></nav><main class=main-content><header class=main-head><h1>Notes</h1></header><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2020/01/buildkit-multi-platform-travis-ci/>Building Multi-Platform Docker Images with Travis CI and BuildKit</a></h2></header><p><em>This is a lengthy note. If you don&rsquo;t quite feel reading and only need the working example, go directly to <a href=https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/.travis.yml>the Travis CI build file</a>.</em></p><p>The more I delve into the world of Raspberry Pi, the more I notice that &ldquo;regular and boring&rdquo; things on ARM are harder than I expected.</p><p>People build and distribute software exclusively for amd64. You read another &ldquo;<em>Kubernetes something</em>&rdquo; tutorial, that went viral on Twitter, and is fancy to try it out. Still, all helm charts, or whatever the author prefered, use Docker images built exclusively for amd64.</p><p>Docker toolchain has added the support for building multi-platform images in 19.x. However, it&rsquo;s available only under the &ldquo;experimental&rdquo; mode. The topic of building multi-platform Docker images yet feels underrepresented.</p><h2 id=but-first-what-are-multi-platform-docker-images>But first, what are multi-platform Docker images?</h2><p>When a client, e.g. Docker client, tries to pull an image, it must negotiate the details about what exactly to pull with the registry. The registry provides a manifest that describes the digest of the requested image, the volumes the image consists of, the platform this image can run on, etc. Optionally, the registry can provide a manifests list, which, as the name suggests, is a list of several manifests bundled into one. With the manifests list in hands, the client can figure out the particular digest of the image it needs to pull.</p><p>So multi-platform Docker images are just several images, whose manifests are bundled into the manifests list.</p><p>Imagine we want to pull the image <a href=https://hub.docker.com/_/golang><code>golang:1.13.6-alpine3.10</code></a>. Docker client will get the manifests list from Dockerhub. This list includes digests of several images, each built for the particular platform. If we&rsquo;re on Raspberry Pi, running the current Raspbian Linux, which is <code>arm/v7</code>, the client will pick the corresponding image&rsquo;s digest. Alternatively, we could choose to pull the image <a href=https://hub.docker.com/r/arm32v7/golang/><code>arm32v7/golang:1.13.6-alpine3.10</code></a> instead, and we ended up with the same image with the <a href=https://hub.docker.com/layers/arm32v7/golang/alpine3.10/images/sha256-d72fa60fb5b9ffc12db9c87340bc9d9f55852570f1efc7d7656f081749a7f0aa>digest <code>d72fa60fb5b9</code></a>. Of course, to use a single universal image name, i.e. <code>golang</code>, on every platform is way more convenient.</p><p>You can read more about manifests <a href=https://docs.docker.com/registry/spec/manifest-v2-2/>in Docker registry documentation</a>.</p><h2 id=does-it-mean-i-need-to-build-different-docker-images-for-each-platform-i-want-to-support>Does it mean I need to build different Docker images, for each platform I want to support?</h2><p>Well, yes. This is how, official images are built.</p><p>For every platform, the image is built and pushed to the registry under the name <code>&lt;platform>/&lt;image>:&lt;tag></code>, e.g. <a href=https://hub.docker.com/r/amd64/golang/><code>amd64/golang:1-alpine</code></a>. And next, a manifests list, that combines all those platform-specific images, is built and pushed with the simple name <code>&lt;image>:&lt;tag></code>.</p><p><a href=https://github.com/moby/buildkit>Docker&rsquo;s BuildKit</a> provides a toolkit that, among other nice things, allows building multi-platform images on a single host. BuildKit is used inside <a href=https://github.com/docker/buildx>Docker&rsquo; buildx project</a>, that is part of the recent Docker version.</p><p>One can use buildx, but, for this post, I wanted to try out, what would it look like to use BuildKit directly. For <a href=https://github.com/profefe/profefe>profefe</a>, the system for continuous profiling of Go services, I set up <a href=https://travis-ci.com/>Travis CI</a>, that builds a multi-platform Docker image and pushes them to Dockerhub.</p><p>profefe is written in Go. That simplifies things, because, thanks to Go compiler, I don&rsquo;t have to think about how to compile code for different platforms. <a href=https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/contrib/docker/Dockerfile>The same Dockerfile</a> will work fine on every platform.</p><p>Here&rsquo;s how &ldquo;deploy&rdquo; stage of the build job looks like (<a href=https://github.com/profefe/profefe/blob/09ff03be6561a7ef88fba7b96d923abd6a413931/.travis.yml>see <code>travis.yml</code> on profefe&rsquo;s GitHub</a>).</p><pre><code>dist: bionic

language: go
go:
  - 1.x

jobs:
  include:
    - stage: deploy docker
      services: docker
      env:
        - PLATFORMS=&quot;linux/amd64,linux/arm64,linux/arm/v7&quot;
      install:
        - docker container run --rm --privileged multiarch/qemu-user-static --reset -p yes
        - docker container run -d --rm --name buildkitd --privileged moby/buildkit:latest
        - sudo docker container cp buildkitd:/usr/bin/buildctl /usr/local/bin/
        - export BUILDKIT_HOST=&quot;docker-container://buildkitd&quot;
      script: skip
      deploy:
        - provider: script
          script: |
            buildctl build \
              --progress=plain \
              --frontend=dockerfile.v0 \
              --local context=. --local dockerfile=. \
              --opt filename=contrib/docker/Dockerfile \
              --opt platform=$PLATFORMS \
              --opt build-arg:VERSION=\&quot;master\&quot; \
              --opt build-arg:GITSHA=\&quot;$TRAVIS_COMMIT\&quot; \
              --output type=image,\&quot;name=profefe/profefe:git-master\&quot;,push=true
          on:
            repo: profefe/profefe
            branch: master
      before_deploy:
        - echo &quot;$DOCKER_PASSWORD&quot; | docker login --username &quot;$DOCKER_USERNAME&quot; --password-stdin
      after_failure:
        - buildctl debug workers ls
        - docker container logs buildkitd
</code></pre><p>It&rsquo;s a lot happening here, but I&rsquo;ll describe the most critical parts.</p><p>Let&rsquo;s start with <code>dist: bionic</code>.</p><p>We run the builds under Ubuntu 18.04 (Bionic Beaver). To be able to build multi-platform images on a single amd64 host, BuildKit uses QEMU to emulate other platforms. That requires Linux kernel 4.8, so even Ubuntu 16.04 (Xenial Xerus) should work.</p><p>The top-level details on how the emulation works are very well described in <a href=https://www.kernel.org/doc/html/latest/admin-guide/binfmt-misc.html>https://www.kernel.org/doc/html/latest/admin-guide/binfmt-misc.html</a></p><p>In short, we tell the component of the kernel (<code>binfmt_misc</code>) to use QEMU when the system executes a binaries built for a different platform. The following call in the &ldquo;install&rdquo; step is what&rsquo;s doing that:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>- docker container run --rm --privileged multiarch/qemu-user-static --reset -p yes
</code></pre></div><p>Under the hood, the container runs a <a href=https://raw.githubusercontent.com/qemu/qemu/master/scripts/qemu-binfmt-conf.sh>shell script from QEMU project</a>, that registers the emulator as an executor of binaries from the external platforms.</p><blockquote><p>If you think, that running a docker container to do the manipulations with the host&rsquo;s OS looks weird, well&mldr; I can&rsquo;t agree more. Probably, a better approach would be to install <a href=https://packages.ubuntu.com/bionic/qemu-user-static>qemu-user-static</a>, which would do the proper setup. Unfortunately, the current package&rsquo;s version for Ubuntu Bionic doesn&rsquo;t do the registration as we need it. I.e. its post-install doesn&rsquo;t add the <code>"F"</code> flag (&ldquo;fix binaries&rdquo;), which is crucial for our goal. Let&rsquo;s just agree,that docker-run will do ok for the demonstrational purpose.</p></blockquote><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>- docker container run -d --rm --name buildkitd --privileged moby/buildkit:latest
- sudo docker container cp buildkitd:/usr/bin/buildctl /usr/local/bin/
- export BUILDKIT_HOST=<span style=color:#a31515>&#34;docker-container://buildkitd&#34;</span>
</code></pre></div><p>This is another &ldquo;docker-run&rsquo;ism&rdquo;. We start BuildKit&rsquo;s <code>buildkitd</code> daemon inside the container, attaching it to the Docker daemon that runs on the host (&ldquo;privileged&rdquo; mode). Next, we copy <code>buildctl</code> binary from the container to the host system and set <code>BUILDKIT_HOST</code> environment variable, so <code>buildctl</code> knew where its daemon runs.</p><blockquote><p>Alternatively, we could install BuildKit from GitHub and run the daemon directly on the build host. YOLO.</p></blockquote><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#00f>before_deploy</span>:
  - echo <span style=color:#a31515>&#34;$DOCKER_PASSWORD&#34;</span> | docker login --username <span style=color:#a31515>&#34;$DOCKER_USERNAME&#34;</span> --password-stdin
</code></pre></div><p>To be able to push the images to the registry, we need to log in providing Docker credentials to host&rsquo;s Docker daemon. The credentials are set as Travis CI&rsquo;s encrypted environment variables ([refer to Travis CI docs])](<a href=https://docs.travis-ci.com/user/environment-variables/))>https://docs.travis-ci.com/user/environment-variables/))</a>.</p><pre><code>buildctl build \
  --progress=plain \
  --frontend=dockerfile.v0 \
  --local context=. --local dockerfile=. \
  --opt filename=contrib/docker/Dockerfile \
  --opt platform=$PLATFORMS \
  --opt build-arg:VERSION=\&quot;master\&quot; \
  --opt build-arg:GITSHA=\&quot;$TRAVIS_COMMIT\&quot; \
  --output type=image,\&quot;name=profefe/profefe:git-master\&quot;,push=true
</code></pre><p>This is the <em>black box</em> where everything happens. Magically!</p><p>We run <code>buildctl</code> stating that it must use the specified Dockerfile; it must build the images for defined platforms (I specified <code>linux/amd64,linux/arm64,linux/arm/v7</code>), create a manifests list tagged as the desired image (<code>profefe/profefe:&lt;version></code>), and push all the images to the registry.</p><p><code>buildctl debug workers ls</code> shows what platforms does BuildKit on this host support. I listed only those I&rsquo;m currently intrested with.</p><p>And that&rsquo;s all. This setup automatically builds and pushes multi-platform Docker images for profefe (<a href=https://hub.docker.com/p/profefe/profefe>https://hub.docker.com/p/profefe/profefe</a>) on a commit to project&rsquo;s &ldquo;master&rdquo; branch on GitHub.</p><hr><p>As I hope you&rsquo;ve seen, support for multi-platform is getting easier and things that were hard a year ago are only mildly annoying now :)</p><p>If you have any comments or suggestions, reach out to me on <a href=https://twitter.com/tvii/status/1221858810006065154>Twitter</a> or discuss this note on <a href=https://www.reddit.com/r/docker/comments/eutrkg/building_multiplatform_docker_images_with_travis/>r/docker Reddit</a>.</p><p>Some more reading on the topic:</p><ul><li><a href=https://github.com/moby/buildkit>Documentation for BuildKit project</a></li><li><a href=https://github.com/docker/buildx#building-multi-platform-images>Building multi-platform images with docker and buildx</a></li><li><a href=https://www.docker.com/blog/docker-official-images-now-multi-platform/>Docker Official Images are now Multi-platform, Docker official announcement</a></li></ul><footer class=article-meta><time datetime=2020-01-27T12:00:00Z>January 27, 2020</time><span class=tag>docker</span><span class=tag>buildkit</span><span class=tag>travis ci</span><span class=tag>raspberry pi</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2020/01/raspi-ubuntu-arm64-k3s/>k3s with Ubuntu Server (arm64) on Raspberry Pi 4</a></h2></header><p>As I&rsquo;ve <a href="https://twitter.com/tvii/status/1215927299557797893?s=20">twitted</a> recently, I&rsquo;m updating one of my Raspberry Pis to <a href=https://ubuntu.com/download/raspberry-pi>Ubuntu Server 19.10 (arm64)</a>.</p><h2 id=one-of-raspberry-pis>&ldquo;One of Raspberry Pis&rdquo;?</h2><p>My home cluster is four <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-2gb">Raspberry Pis 4 (2GB)</a>; all connected to my internet router through ethernet and
powered with <a href="https://www.amazon.de/gp/product/B00PTLSH9G/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&psc=1">60W 6 USB-ports charger</a>. All Pis build a small kubernetes cluster that runs with <a href=https://k3s.io/>k3s</a>.</p><p>All by one Pis run on <a href=https://www.raspberrypi.org/downloads/raspbian/>Raspbian Buster Lite</a> and this setup&rsquo;s been working pretty well until I&rsquo;ve found out,
<a href=https://www.aerospike.com/>Aerospike</a>, a database I required to run for a testing lab, only works on a 64-bit OS.</p><p>Luckily, <a href=https://ubuntu.com/download/raspberry-pi>Ubuntu Server has an arm64 version</a> built for Raspberry Pi. Thus, my working plan is to switch one Pi
to Ubuntu, compile and run a single-instance Aerospike server (<em>and any other components, that require a 64-bit OS</em>) on this Pi, and provide a kubernetes service in front of the DB, so other components in the cluster could access it as if it was
fully managed by kubernetes.</p><h2 id=the-setup>The Setup</h2><p>Setting up Ubuntu Server on a Pi was smooth. All I did was flushing the image with 19.10 OS to an SD card, as described in <a href=https://ubuntu.com/download/iot/installation-media>Ubuntu wiki</a>. That is, the headless setup worked out of the box, and after I inserted the card into the PI and connected it to the router, I managed to SSH into the system:</p><pre><code>$ ssh ubuntu@192.168.10.18
</code></pre><p>The default password for <code>ubuntu</code> user is <code>ubuntu</code>. The system asks to change the password on the first login.</p><p>The first thing to do after installing the system:</p><pre><code>$ sudo apt-get update
$ sudo apt-get upgrade -y
</code></pre><p>Disable &ldquo;message of the day&rdquo; (<code>motd</code>) to speed SSH login.
For that I commented out the following lines in <code>/etc/pam.d/login</code> and <code>/etc/pam.d/sshd</code>:</p><pre><code>#session    optional     pam_motd.so  motd=/run/motd.dynamic
#session    optional     pam_motd.so noupdate
</code></pre><p>Reduce GPU memory split. <em>I truly don&rsquo;t know if that even makes sense, tbh; read about memory split on <a href=https://www.raspberrypi.org/documentation/configuration/config-txt/memory.md>Raspberry PI config-txt wiki</a>.</em> I added the following to <code>/boot/firmware/usercfg.txt</code>:</p><pre><code>gpu_mem=16
</code></pre><p>To run Kubernetes or Docker, the kernel needs some cgroup options. On Ubuntu Server, the configuration is in <code>/boot/firmware/nobtcmd.txt</code> (<em>refer to <code>cmdline=nobtcmd.txt</code> in <code>/boot/firmware/nobtcfg.txt</code></em>). Add the following to the end of the file:</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1
</code></pre><p>Reboot the Pi, re-login, and all is ready to <a href=https://rancher.com/docs/k3s/latest/en/installation/>install k3s-agent</a>:</p><pre><code>$ curl -sfL https://get.k3s.io  | K3S_URL=&quot;https://&lt;k3s-master-pi&gt;:6443&quot; K3S_TOKEN=&quot;&lt;k3s-token&gt;&quot; sh -
</code></pre><p>After the agent installed and running, check the Pi was added to kubernetes cluster:</p><pre><code>pi@pi-1:~ $ sudo kubectl get node -o wide
NAME   STATUS   ROLES    AGE   VERSION         INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION      CONTAINER-RUNTIME
pi-1   Ready    master   30d   v1.17.0+k3s.1   192.168.10.16   &lt;none&gt;        Raspbian GNU/Linux 10 (buster)   4.19.75-v7l+        containerd://1.3.0-k3s.5
pi-2   Ready    &lt;none&gt;   47h   v1.17.0+k3s.1   192.168.10.14   &lt;none&gt;        Raspbian GNU/Linux 10 (buster)   4.19.75-v7l+        containerd://1.3.0-k3s.5
pi-3   Ready    &lt;none&gt;   47h   v1.17.0+k3s.1   192.168.10.15   &lt;none&gt;        Raspbian GNU/Linux 10 (buster)   4.19.75-v7l+        containerd://1.3.0-k3s.5
pi-4   Ready    &lt;none&gt;   10h   v1.17.0+k3s.1   192.168.10.18   &lt;none&gt;        Ubuntu 19.10                     5.3.0-1014-raspi2   containerd://1.3.0-k3s.5
</code></pre><p>That is for today. The next steps are to figure out how to <a href=https://github.com/aerospike/aerospike-server/pull/6>build Aerospike on arm64</a>, but this is a story for another day.</p><h3 id=update-2020-01-15>Update (2020-01-15)</h3><p>I&rsquo;ve managed to build and run Aerospike server for arm64! See <a href=https://github.com/narqo/aerospike-server/tree/make-arm64v8>make-arm64v8 branch</a>
in my fork of aerospike-server and <a href=https://gist.github.com/narqo/98e95760852cee9a64c3557026b3fe4a>the gist</a> with my systemd services and configs.</p><footer class=article-meta><time datetime=2020-01-11T12:00:00Z>January 11, 2020</time><span class=tag>raspberry pi</span><span class=tag>arm64</span><span class=tag>aarch64</span><span class=tag>k3s</span><span class=tag>kubernetes</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2019/12/the-fireside-edition/>The Fireside Edition</a></h2></header><p>After listening to the &ldquo;Fireside edition&rdquo; of <a href=https://changelog.com/gotime/110>Go Time FM</a>, I questioned myself, how would I answered the questions the hosts discussed.</p><p>Because no one has asked, you are very welcome:</p><h2 id=1-if-you-had-two-weeks-to-spend-on-a-personal-go-project-what-would-you-work-on>1. If you had two weeks to spend on a personal Go project, what would you work on?</h2><p>I really want to invest more time for <a href=https://github.com/profefe/profefe>profefe</a>. Specifically,
on implementing an analyser of stored profiles: the thing that would help to make sense of the data,
showing how the performance of an instance, a node, or a cluster had changed over the period of time;
how different parts of the codebase had influenced the performance of the application.</p><p>Recently Amazon has announced CodeGuru profiler (currently Java-only). From <a href=https://aws.amazon.com/codeguru/faqs/#Amazon_CodeGuru_Profiler>the description</a> it feels
exactly what I pictured in my head when I started the project.</p><p>Another topic that I would like to invest more time on is the understanding of the ecosystem around/inside Kubernetes.
During the past two years, I slowed down the consumption of the DevOps/SRE topics, mostly due to the specific
state of the infrastructure in our company. But, &ldquo;<em>k8s is the new linux</em>", regardless of what one&rsquo;s opinion on that.
Even profefe recently has ended up having a <a href=https://github.com/profefe/kube-profefe>kube-profefe</a> (<em>a bridge between profefe and Kubernetes</em>), contributed and maintained by other people.</p><h2 id=2-what-annoys-you-about-go-of-2019>2. What annoys you about Go of 2019?</h2><p>The same small things that annoyed me in Go 1.4: <code>var</code>, <code>new</code>, <code>make</code> and &ldquo;naked return&rdquo;. Sure, I understand that they all ended up in the language for a reason. But I simply don&rsquo;t like the &ldquo;magic&rdquo; of <code>make</code>, which works only with particular types;
the two ways of defining a variable (<code>var</code> or <code>:=</code>), or a pointer to an instance of a type (<code>new</code> or <code>&T{}</code>).</p><p>One new thing, though. Go modules&rsquo; semver imports. But I can&rsquo;t say anything new about that. Probably, I just need to embrase them. Go 1.14 looks like a version where I might completely switch to modules, thanks to better handling of vendored dependencies.</p><h2 id=3-whats-your-ideal-working-environment>3. What&rsquo;s your ideal working environment?</h2><p>That always surprises me. Lots of people keep saying that working from home is their ideal environment or even a factor
that influence their job offers choice. I don&rsquo;t like to work at home. The only time when I feel productive when stay home is in the nights. A cafe or a co-working works sometimes. But I like working in a big office space. I don&rsquo;t know why.</p><p>Of course, open-plan offices can be very different. Yandex&rsquo;s &ldquo;Red Rose&rdquo; is still the best space I ever worked in. I heard they do excursions around the Moscow&rsquo;s office now.</p><h3 id=31-something-on-pair-programming>3.1. Something on pair-programming?</h3><p><em>Since I wrote about Yandex.</em></p><p>Some people thing pair-programming is a sort of a super-power. It&rsquo;s, and it&rsquo;s not.
You can&rsquo;t just put yourself in an environment, where someone is watching how you write the code while trying to hold a conversation about the code architecture. Pair-programming is a skill to master. But it pays off.</p><p>The pair-(trio actually)-programming sessions we did in Yandex, when we worked on <a href=https://github.com/bem/bem-core>bem-core</a>, was the most significant skill boost I had during the five+ years their.</p><p>Of course, the positive experience comes from your peers. In my case, they were people with a huge baggage of knowledge and practice of working, talking, debating with each other. Like, out of nowhere, you get the understanding of what
types of questions you must ask; when it is important to spend more time on thinking and when you can make a small hack.</p><h2 id=4-your-advice-to-you-junior-developer-self>4. Your advice to you junior-developer self?</h2><p>Don&rsquo;t overthink and afraid of starting anything. Trying something by making a raw, dirty, barely-working prototype will give you way more knowledge than thinking about how to do that.</p><footer class=article-meta><time datetime=2019-12-23T12:00:00Z>December 23, 2019</time><span class=tag>go</span><span class=tag>go time fm</span><span class=tag>askme</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2019/10/go-bytes-string-conversion/>[]byte to string conversion</a></h2></header><p>Go has an old wiki page, titled &ldquo;<a href=https://github.com/golang/go/wiki/CompilerOptimizations>Compiler And Runtime Optimizations</a>".</p><p>The part I like most there is different cases where compiler doesn&rsquo;t allocate memory for <code>string</code> to <code>[]byte</code> conversions:</p><blockquote><p>For a map m of type <code>map[string]T</code> and <code>[]byte b</code>, <code>m[string(b)]</code> doesn&rsquo;t allocate (the temporary string copy of the byte slice isn&rsquo;t made)</p></blockquote><p>Turned out, since this wiki page was written, more similar optimisations were added to the compiler.</p><p>As it&rsquo;s in Go 1.12+ the following cases are also listed in <a href=https://github.com/golang/go/blob/release-branch.go1.12/src/runtime/string.go#L128-L153><code>runtime/string.go</code></a>:</p><ul><li>Strings comcatenation</li></ul><p>For the case <code>"&lt;" + string(b) + ">"</code>, where <code>b</code> is <code>[]byte</code> no extra copying of <code>b</code> is needed.</p><ul><li>Comparison</li></ul><pre><code>if string(b) == &quot;foo&quot; { ··· }
</code></pre><p>In the code above, <code>b []byte</code> also won&rsquo;t be copied.</p><hr><p>There are still cases where compiler can&rsquo;t optimise the code for us. In some of those cases
it&rsquo;s fine to do string to bytes conversion using a so called &ldquo;<code>unsafe</code> trick&rdquo; (accessing string&rsquo;s underling
data directly, with out copying the data from string to bytes and vice versa). One can find several
ways of performing the trick, but none of them seems &ldquo;the one that must be used&rdquo;.</p><p>After years of episodic discussions, a collegue of mine assembled the list of different conserns and about
the proper way of doing it (<em>see &ldquo;<a href=https://groups.google.com/d/topic/golang-nuts/Zsfk-VMd_fU/discussion>unsafe conversion between string &lt;-> []byte</a>&rdquo; topic on golang-nuts forum</em>).
Thanks to replies from Go team, our most valid way of doing it is following:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:green>// Refer to github.com/fmstephe/unsafeutil
</span><span style=color:green></span>
<span style=color:#00f>type</span> stringHeader <span style=color:#00f>struct</span> {
	data      unsafe.Pointer
	stringLen <span style=color:#2b91af>int</span>
}

<span style=color:#00f>type</span> sliceHeader <span style=color:#00f>struct</span> {
	data     unsafe.Pointer
	sliceLen <span style=color:#2b91af>int</span>
	sliceCap <span style=color:#2b91af>int</span>
}

<span style=color:#00f>func</span> StringToBytes(s <span style=color:#2b91af>string</span>) (b []<span style=color:#2b91af>byte</span>) {
	stringHeader := (*stringHeader)(unsafe.Pointer(&amp;s))
	sliceHeader := (*sliceHeader)(unsafe.Pointer(&amp;b))
	sliceHeader.data = stringHeader.data
	sliceHeader.sliceLen = len(s)
	sliceHeader.sliceCap = len(s)
	<span style=color:#00f>return</span> b
}

<span style=color:#00f>func</span> BytesToString(b []<span style=color:#2b91af>byte</span>) (s <span style=color:#2b91af>string</span>) {
	sliceHeader := (*sliceHeader)(unsafe.Pointer(&amp;b))
	stringHeader := (*stringHeader)(unsafe.Pointer(&amp;s))
	stringHeader.data = sliceHeader.data
	stringHeader.stringLen = len(b)
	<span style=color:#00f>return</span> s
}
</code></pre></div><footer class=article-meta><time datetime=2019-10-08T12:00:00Z>October 8, 2019</time><span class=tag>go</span><span class=tag>µ-benchmarks</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2019/09/github-actions-and-gopath/>Github Actions and GOPATH</a></h2></header><p>The other day I received my beta access to <a href=https://github.com/features/actions>GitHub Actions</a>. To try them out I picked an existing pet project and created a <em>workflow</em> using a Go project template provided by GitHub. As it&rsquo;s in <em>September 2019</em>, their template defines the sequence of steps: setup Go, checkout code, get dependencies, build. This is not exactly how I used to do it.</p><p>My project is a <em>classic Go service</em> ;) meaning: it uses vendoring and doesn&rsquo;t use Go modules. So no need for &ldquo;get dependencies&rdquo; step. And it requires to be inside the <code>GOPATH</code>. With that, the provided workflow needed some adjustment.</p><p>After some trials and errors, I&rsquo;ve managed to make <code>checkout</code> step to clone the repo into the correct destination inside the <code>GOPATH</code>. Here is the final workflow:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#00f>name</span>: Run Go test
<span style=color:#00f>on</span>: [pull_request]
<span style=color:#00f>jobs</span>:
  <span style=color:#00f>test</span>:
    <span style=color:#00f>strategy</span>:
      <span style=color:#00f>matrix</span>:
        <span style=color:#00f>go-version</span>: [1.12.9]

    <span style=color:#00f>runs-on</span>: ubuntu-latest

    <span style=color:#00f>steps</span>:
      - <span style=color:#00f>uses</span>: actions/setup-go@v1
        <span style=color:#00f>with</span>:
          <span style=color:#00f>go-version</span>: ${{ matrix.go-version }}

      - <span style=color:#00f>uses</span>: actions/checkout@v1
        <span style=color:#00f>with</span>:
          <span style=color:#00f>path</span>: ./src/github.com/${{ github.repository }}
          <span style=color:#00f>fetch-depth</span>: 5

      - <span style=color:#00f>run</span>: make test
        <span style=color:#00f>env</span>:
          <span style=color:#00f>GOPATH</span>: ${{ runner.workspace }}
</code></pre></div><p>Note, how <code>actions/checkout@v1</code> above uses custom <code>path</code> input parameter. I set the path to <code>./src/github.com/${{ github.repository }}</code>, so the project is checked out to <code>src</code> directory in the runners&rsquo;s workspace, which I later pass as the value of <code>GOPATH</code> to the &ldquo;make test&rdquo; step. The leading dot in <code>./src</code> seems very important — I&rsquo;ve spent the majority of the time trying to figure out that part — refer to <a href=https://github.com/actions/checkout/issues/41>this issue</a>.</p><p><a href=https://github.com/profefe/profefe/actions>See the workflow in action</a>.</p><p>To learn more about those <code>${{ ··· }}</code> &ldquo;macroses&rdquo; I suggest looking at the Actions&rsquo; &ldquo;<a href=https://help.github.com/en/articles/contexts-and-expression-syntax-for-github-actions>Contexts and expression syntax</a>&rdquo; documentation.</p><footer class=article-meta><time datetime=2019-09-19T12:00:00Z>September 19, 2019</time><span class=tag>go</span><span class=tag>github actions</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2019/09/go-http-headers/>Go's net/http.Headers</a></h2></header><p>One probably knows that <code>net/http.Headers</code> is no more than <code>map[string][]string</code> with extra specific methods. A usual way to initialise and populate such data-structure from an external representation is something like that:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#00f>type</span> Header <span style=color:#00f>map</span>[<span style=color:#2b91af>string</span>][]<span style=color:#2b91af>string</span>

<span style=color:#00f>func</span> (h Header) Add(key, val <span style=color:#2b91af>string</span>) {
    <span style=color:#00f>if</span> val == <span style=color:#a31515>&#34;&#34;</span> {
        <span style=color:#00f>return</span>
    }
    h[key] = append(h[key], val)
}

<span style=color:#00f>func</span> main() {
    h := make(Header)
    h.Add(<span style=color:#a31515>&#34;Host&#34;</span>, <span style=color:#a31515>&#34;example.com&#34;</span>)
    h.Add(<span style=color:#a31515>&#34;Via&#34;</span>, <span style=color:#a31515>&#34;a.example.com&#34;</span>)
    h.Add(<span style=color:#a31515>&#34;Via&#34;</span>, <span style=color:#a31515>&#34;b.example.com&#34;</span>)
}
</code></pre></div><p>From the code above, one can notice that we allocated a new slice of strings for every unique key that we added to headers. For things like HTTP headers, that&rsquo;re automatically parsed for every incoming request, this bunch of tiny allocations is something we&rsquo;d like to avoid.</p><p>I was curious to know if Go&rsquo;s standard library cares about that.</p><p>Looking at the implementation of <a href=https://golang.org/pkg/net/textproto/#Reader.ReadMIMEHeader><code>net/textproto.Reader.ReadMIMEHeader()</code></a>, which&rsquo;s used in the standard
HTTP server, or Go 1.13’s new <a href=https://golang.org/pkg/net/http/#Header.Clone><code>net/http.Header.Copy()</code></a>, it turned out they solve the problem quit elegantly.</p><p>We know that for a majority of cases, HTTP headers are an immutable key-value pair, where most of the keys have a single value. Instead of allocating a separate slice for a unique key, Go pre-allocates a continues slice for values and refers to a sub-slice of this slice for all keys.</p><p>Knowing that, we can refactor the initial <code>Header.Add</code> as the following:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#00f>type</span> Header <span style=color:#00f>map</span>[<span style=color:#2b91af>string</span>][]<span style=color:#2b91af>string</span>

<span style=color:#00f>func</span> (h Header) add(vv []<span style=color:#2b91af>string</span>, key, val <span style=color:#2b91af>string</span>) []<span style=color:#2b91af>string</span> {
    <span style=color:#00f>if</span> val == <span style=color:#a31515>&#34;&#34;</span> { <span>·</span><span>·</span><span>·</span> }

    <span style=color:green>// fast path for KV pair of a single value
</span><span style=color:green></span>    <span style=color:#00f>if</span> h[key] == <span style=color:#00f>nil</span> {
        vv = append(vv, value)
        h[key] = vv[:1:1]
        <span style=color:#00f>return</span> vv[1:]
    }

    <span style=color:green>// slow path, when KV pair has two or more values
</span><span style=color:green></span>    h[key] = append(h[key], val)
    <span style=color:#00f>return</span> vv
}

<span style=color:#00f>func</span> main() {
    h := make(Header)
    <span style=color:green>// net/textprotocol pre-counts total number of request&#39;s headers
</span><span style=color:green></span>    <span style=color:green>// to allocate the slice of known capacity
</span><span style=color:green></span>    vv := make([]<span style=color:#2b91af>string</span>, 0)

    vv = h.add(vv, <span style=color:#a31515>&#34;Host&#34;</span>, <span style=color:#a31515>&#34;example.com&#34;</span>)
    vv = h.add(vv, <span style=color:#a31515>&#34;Via&#34;</span>, <span style=color:#a31515>&#34;a.example.com&#34;</span>)
}
</code></pre></div><p>Note that we use <code>vv[:1:1]</code> to create a <a href=https://golang.org/ref/spec#Slice_expressions>subslice of the fixed capacity</a> (length 1, capacity 1).</p><p>If there is a KV-pair that has several values, e.g. &ldquo;Via&rdquo; header, <code>Add</code> will allocate a separate slice for that key, doubling its capacity.</p><footer class=article-meta><time datetime=2019-09-04T12:00:00Z>September 4, 2019</time><span class=tag>go</span><span class=tag>µ-benchmarks</span></footer></article><article class=article data-weight=0><header class=article-head><h2><a href=/notes/2019/09/hello-world/>Hello World</a></h2></header><p>Let&rsquo;s create a blog. But let&rsquo;s call them &ldquo;notes&rdquo;.</p><p>Because sometimes there are thoughts I want to share with you. Some of them might even be larger than a tweet.</p><footer class=article-meta><time datetime=2019-09-01T12:00:00Z>September 1, 2019</time></footer></article></main><footer class=main-footer>© 2020 VLDMR</footer></body></html>